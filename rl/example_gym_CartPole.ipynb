{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO40nlOpya5b7dgNNooTuGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chonholee/tutorial/blob/main/rl/example_gym_CartPole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example CartPole"
      ],
      "metadata": {
        "id": "K_9XMAwyI65O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "for episode in range(10):\n",
        "\n",
        "    env.reset()\n",
        "\n",
        "    total_reward = 0\n",
        "\n",
        "    for t in range(50):\n",
        "\n",
        "        action = env.action_space.sample()\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        total_reward += reward\n",
        "\n",
        "        print(episode, t, state, reward, total_reward, done)\n",
        "\n",
        "        if done:\n",
        "            print('Failed')\n",
        "            break"
      ],
      "metadata": {
        "id": "X6QO1RfDNc-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "アニメーション動画の保存"
      ],
      "metadata": {
        "id": "oZ1DL_30Otqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for episode in range(10):\n",
        "\n",
        "    env.reset()\n",
        "\n",
        "    for t in range(50):\n",
        "\n",
        "        action = env.action_space.sample()\n",
        "        env.step(action)\n",
        "        frames.append(env.render(mode='rgb_array'))\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "patch = plt.imshow(frames[0])\n",
        "plt.axis('off')\n",
        "\n",
        "def animate(i):\n",
        "    patch.set_data(frames[i])\n",
        "\n",
        "anim = animation.FuncAnimation(\n",
        "    plt.gcf(), animate, frames=len(frames),interval=50)\n",
        "\n",
        "anim.save('example.mp4', \"ffmpeg\")"
      ],
      "metadata": {
        "id": "FaC_NJ_YKLfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q学習（クラス化）"
      ],
      "metadata": {
        "id": "qV0xhUHtOyiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "\n",
        "import gym\n",
        "\n",
        "# 各状態の分割数\n",
        "NUM_DIZITIZED = 6\n",
        "\n",
        "# 学習パラメータ\n",
        "GAMMA = 0.99  # 時間割引率\n",
        "ETA = 0.5  # 学習係数\n",
        "\n",
        "class State:\n",
        "    def __init__(self, num_states, num_actions):\n",
        "        # 行動数を取得\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        # Qテーブルを作成　(分割数^状態数)×(行動数)\n",
        "        self.q_table = np.random.uniform(\n",
        "            low=-1,\n",
        "            high=1,\n",
        "            size=(NUM_DIZITIZED**num_states, num_actions)\n",
        "        )\n",
        "\n",
        "    def bins(self, clip_min, clip_max, num):\n",
        "        # 観測した状態デジタル変換する閾値を求める\n",
        "        return np.linspace(clip_min, clip_max, num + 1)[1:-1]\n",
        "\n",
        "    def analog2digitize(self, observation):\n",
        "        #状態の離散化\n",
        "        cart_pos, cart_v, pole_angle, pole_v = observation\n",
        "        digitized = [\n",
        "            np.digitize(cart_pos, bins=self.bins(-2.4, 2.4, NUM_DIZITIZED)),\n",
        "            np.digitize(cart_v, bins=self.bins(-3.0, 3.0, NUM_DIZITIZED)),\n",
        "            np.digitize(pole_angle, bins=self.bins(-0.5, 0.5, NUM_DIZITIZED)),\n",
        "            np.digitize(pole_v, bins=self.bins(-2.0, 2.0, NUM_DIZITIZED))\n",
        "        ]\n",
        "        return sum([x * (NUM_DIZITIZED**i) for i, x in enumerate(digitized)])\n",
        "\n",
        "    def update_Q_table(self, observation, action, reward, observation_next):\n",
        "        # 状態の離散化\n",
        "        state = self.analog2digitize(observation)\n",
        "        state_next = self.analog2digitize(observation_next)\n",
        "        Max_Q_next = max(self.q_table[state_next][:])\n",
        "\n",
        "        # Qテーブルを更新(Q学習)\n",
        "        self.q_table[state, action] = self.q_table[state, action] + \\\n",
        "            ETA * (reward + GAMMA * Max_Q_next - self.q_table[state, action])\n",
        "\n",
        "    def decide_action(self, observation, episode):\n",
        "        # ε-greedy法で行動を選択する\n",
        "        state = self.analog2digitize(observation)\n",
        "        epsilon = 0.5 * (1 / (episode + 1))\n",
        "\n",
        "        if epsilon <= np.random.uniform(0, 1):\n",
        "            # 最も価値の高い行動を行う。\n",
        "            action = np.argmax(self.q_table[state][:])\n",
        "        else:\n",
        "            # 適当に行動する。\n",
        "            action = np.random.choice(self.num_actions)\n",
        "        return action\n"
      ],
      "metadata": {
        "id": "rXd0EXb5u6hb"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, num_states, num_actions):\n",
        "        # 環境を生成\n",
        "        self.state = State(num_states, num_actions)\n",
        "\n",
        "    def update_Q_function(self, observation, action, reward, observation_next):\n",
        "        # Qテーブルの更新\n",
        "        self.state.update_Q_table(observation, action, reward, observation_next)\n",
        "\n",
        "    def get_action(self, observation, step):\n",
        "        # 行動\n",
        "        action = self.state.decide_action(observation, step)\n",
        "        return action"
      ],
      "metadata": {
        "id": "kL38szI505JN"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最大のステップ数\n",
        "MAX_STEPS = 100\n",
        "# 最大の試行回数\n",
        "NUM_EPISODES = 500\n",
        "# 成功とみなすステップ数\n",
        "SUCESS_STEPS=50\n",
        "# 連続成功回数\n",
        "SUCESS_CONSECUTIVE_EISODES=5\n",
        "\n",
        "class Environment():\n",
        "    def __init__(self, toy_env):\n",
        "        # 環境名\n",
        "        self.env_name = toy_env\n",
        "        # 環境を生成\n",
        "        self.env = gym.make(toy_env)\n",
        "        # 状態数を取得\n",
        "        num_states = self.env.observation_space.shape[0]\n",
        "        # 行動数を取得\n",
        "        num_actions = self.env.action_space.n\n",
        "        # Agentを生成\n",
        "        self.agent = Agent(num_states, num_actions)\n",
        "\n",
        "    def run(self):\n",
        "        complete_episodes = 0 # 成功数\n",
        "        step_list = []\n",
        "        is_episode_final = False  # 最後の試行\n",
        "        is_failed = False\n",
        "        frames = []  # 画像を保存する変数\n",
        "\n",
        "        # 試行数分繰り返す\n",
        "        for episode in range(NUM_EPISODES):\n",
        "\n",
        "            observation = self.env.reset()  # 環境の初期化\n",
        "\n",
        "            for step in range(MAX_STEPS):\n",
        "\n",
        "                # 最後の試行のみ画像を保存する。\n",
        "                if is_episode_final or is_failed:\n",
        "                    frames.append(self.env.render(mode='rgb_array'))\n",
        "\n",
        "                # 行動を求める\n",
        "                action = self.agent.get_action(observation, episode)\n",
        "                # 行動a_tの実行により、s_{t+1}, r_{t+1}を求める\n",
        "                observation_next, _, done, _ = self.env.step(action)\n",
        "\n",
        "                # 報酬を与える\n",
        "                if done:  # ステップ数がMAX経過するか、一定角度以上傾くとdoneはtrueになる\n",
        "                    if step < SUCESS_STEPS:\n",
        "                        reward = -1  # 失敗したので-1の報酬を与える\n",
        "                        complete_episodes = 0  # 成功数をリセット\n",
        "                    else:\n",
        "                        reward = 1  # 成功したので+1の報酬を与える\n",
        "                        complete_episodes += 1  # 連続成功記録を更新\n",
        "                else:\n",
        "                    reward = 0\n",
        "\n",
        "                # Qテーブルを更新する\n",
        "                self.agent.update_Q_function(observation, action, reward, observation_next)\n",
        "\n",
        "                # 観測の更新\n",
        "                observation = observation_next\n",
        "\n",
        "                # 終了時の処理\n",
        "                if done:\n",
        "                    print('%d Episode finished after %f time steps / num_success %d' %\n",
        "                           (episode, step, complete_episodes))\n",
        "\n",
        "                    step_list.append(step+1)\n",
        "                    break\n",
        "\n",
        "            if is_episode_final or is_failed:\n",
        "                es = np.arange(0, len(step_list))\n",
        "                plt.plot(es, step_list)\n",
        "                plt.savefig(\"cartpole.png\")\n",
        "                plt.figure()\n",
        "                patch = plt.imshow(frames[0])\n",
        "                plt.axis('off')\n",
        "\n",
        "                def animate(i):\n",
        "                    patch.set_data(frames[i])\n",
        "\n",
        "                anim = animation.FuncAnimation(plt.gcf(), animate,\n",
        "                                               frames=len(frames),interval=50)\n",
        "\n",
        "                # 最後の試行を動画ファイルに保存\n",
        "                if is_episode_final:\n",
        "                    anim.save(self.env_name+'.mp4', \"ffmpeg\")\n",
        "                if is_failed:\n",
        "                    anim.save(self.env_name+'_failed.mp4', \"ffmpeg\")\n",
        "                break\n",
        "\n",
        "            # 指定回連続成功したら最後の試行を行って結果を描画する\n",
        "            if complete_episodes >= SUCESS_CONSECUTIVE_EISODES:\n",
        "                print(f'--- {SUCESS_CONSECUTIVE_EISODES}回連続成功 ---')\n",
        "                is_episode_final = True\n",
        "\n",
        "            if episode == NUM_EPISODES-2:\n",
        "                print('--- 失敗：学習不足 ---')\n",
        "                is_failed = True"
      ],
      "metadata": {
        "id": "holCnYwH08ja"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOY = \"CartPole-v1\"\n",
        "\n",
        "def main():\n",
        "    cartpole = Environment(TOY)\n",
        "    cartpole.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "4b-gTR-_1G0n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}