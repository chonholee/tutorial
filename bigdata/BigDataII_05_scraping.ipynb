{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxAgzwhF0yiLh0f48if9Nz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chonholee/tutorial/blob/main/bigdata/BigDataII_05_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-Dn2B8rWdeq"
      },
      "source": [
        "# いつものDriveマウント\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/MyDrive/[xxx]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0L8pdnQq9Zl"
      },
      "source": [
        "# スクレイピング\n",
        "\n",
        "# 演習１"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Webスクレイピング用ライブラリ\n",
        "\n",
        "RequestsはWebサイトからHTMLデータの取得によく用いられる。\n",
        " \n",
        "その後、取得したデータからBeautiful Soupなどのライブラリを用いて必要な情報のみを抽出する。"
      ],
      "metadata": {
        "id": "g1pK5BbUmc-h"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tvr549NWmGS"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1RYzEP_Q2tT"
      },
      "source": [
        "url = 'https://chonholee.github.io/tutorial/index.html'\n",
        "response = requests.get(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6crPnBgoX8Vz"
      },
      "source": [
        "# https://developer.mozilla.org/ja/docs/Web/HTTP/Status\n",
        "\n",
        "response.status_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Dian5jX_X6"
      },
      "source": [
        "response.encoding #文字コード"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS8OgiUzYC6e"
      },
      "source": [
        "response.content #取得した内容"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WysbcC2bYKN5"
      },
      "source": [
        "soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJTM9ltJPm6s"
      },
      "source": [
        "soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wnn2f-mYOzB"
      },
      "source": [
        "soup.title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0me6DdcYU4C"
      },
      "source": [
        "soup.title.string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc3UEV7djYQx"
      },
      "source": [
        "### HTML要素を取得する\n",
        "### find_all() や select() などの使い方\n",
        "https://gammasoft.jp/blog/difference-find-and-select-in-beautiful-soup-of-python/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTD0GTIYRCuZ"
      },
      "source": [
        "# ホームページのソースを見ながら、取得したい情報のタグを記入\n",
        "\n",
        "# <body> 取得してみる\n",
        "\n",
        "#--- here ---#\n",
        "result = \n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLLhu_fXkHNc"
      },
      "source": [
        "# ページ内の全てのリンク(<a>)の名前とアドレスとを抽出する\n",
        "\n",
        "#--- here ---#\n",
        "for r in\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCL3uOORpRtE"
      },
      "source": [
        "# ページ内の全てのリンクアドレス(\"href\")をリストにする\n",
        "\n",
        "#--- here ---#\n",
        "links = \n",
        "links"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 例：株価の取得"
      ],
      "metadata": {
        "id": "dz_4bSJnokNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.nikkei.com/markets/kabu/\"\n",
        "\n",
        "#--- here ---#\n",
        "res = \n",
        "soup = "
      ],
      "metadata": {
        "id": "jX3PjTsjoRo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#--- here ---#\n",
        "price = \n",
        "print(price.text)"
      ],
      "metadata": {
        "id": "OrrE24ICqoK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 例：ヤフートップニュースの取得"
      ],
      "metadata": {
        "id": "XXYLAmyysJhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.yahoo.co.jp/'\n",
        "\n",
        "#--- here ---#\n",
        "res = \n",
        "soup = \n",
        "\n",
        "# リンク取得して確認してみる\n",
        "#--- here ---#\n",
        "elems = \n",
        "elems"
      ],
      "metadata": {
        "id": "nvRD0rkopaB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# 関連情報だけ抽出する\n",
        "#--- here ---#\n",
        "elems = \n",
        "elems"
      ],
      "metadata": {
        "id": "SedGAu2zq6DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elems[0].text"
      ],
      "metadata": {
        "id": "WabHO7xHsgZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elems[0].attrs['href']"
      ],
      "metadata": {
        "id": "bmATUqYRp19E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 全トップニュースの見出しとリンクを出力\n",
        "#--- here ---#\n",
        "for elem in elems:\n",
        "    print(elem.text, elem.attrs['href'])"
      ],
      "metadata": {
        "id": "RazqU5ipsY8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caKA6O4ZklD1"
      },
      "source": [
        "# 演習２　テーブル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXRmUzq8kkfu"
      },
      "source": [
        "url = 'https://chonholee.github.io/tutorial/bigdata/test-table.html'\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVqdv3Srk9hR"
      },
      "source": [
        "# header 抽出\n",
        "#--- here ---#\n",
        "result = \n",
        "for a in result:\n",
        "    print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjPIdunblwdh"
      },
      "source": [
        "### 2-2　取得したデータをData Frameとして保存する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MJIa3kEk9EQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "th_list = []\n",
        "td_list = []\n",
        "#--- here ---#\n",
        "for a in soup.find_all(   ):\n",
        "    th_list.append(a.string)\n",
        "\n",
        "#--- here ---#\n",
        "for a in soup.find_all(   ):\n",
        "    td_list.append(a.string)\n",
        "\n",
        "print(th_list)\n",
        "print(td_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwYEVU32pD_e"
      },
      "source": [
        "# dataframeとして保存する\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(np.array([th_list, td_list]).T, columns=['項目', '値'])\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9H81evIfg77"
      },
      "source": [
        "df.to_csv('data.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9zjNWuFlVnX"
      },
      "source": [
        "# 演習３　画像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymyjEf0FYdSD"
      },
      "source": [
        "r = requests.get('https://chonholee.github.io/tutorial/bigdata/test-image.html')\n",
        "\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "\n",
        "soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blj6WeXYYihR"
      },
      "source": [
        "# soup.find('img') # 一つ\n",
        "\n",
        "soup.find_all('img') # 全部"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtxnCaUImIHn"
      },
      "source": [
        "soup.find('img')['src']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHULAiOBm6tk"
      },
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "page_dir = 'https://chonholee.github.io/tutorial/bigdata/'\n",
        "\n",
        "img_url = soup.find('img')['src']\n",
        "\n",
        "img_binary = io.BytesIO(requests.get(page_dir+img_url).content) #画像のURLから画像をバイナリーデータに変換\n",
        "\n",
        "img = Image.open(img_binary) #バイナリーデータを画像化"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpsjHJkl4Sqs"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1VjRuPG4ytS"
      },
      "source": [
        "### 3-2 imgタグすべてを取得して画像を保存する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj7Bb4uypq0w"
      },
      "source": [
        "img_tag_list = soup.find_all('img') #imgタグをすべて取得\n",
        "\n",
        "img_tag_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftyOE7lM4md4"
      },
      "source": [
        "for i, img_tag in enumerate(img_tag_list):\n",
        "\n",
        "    img_url = img_tag['src']\n",
        "    img_binary = io.BytesIO(requests.get(page_dir+img_url).content)\n",
        "    img = Image.open(img_binary)\n",
        "    \n",
        "    img.save('{}.jpg'.format(i)) #保存"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUhSd_bNhYht"
      },
      "source": [
        "# 実践　プロ野球データ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACZnSluYhYGw"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as BS\n",
        "\n",
        "# HTMLを取得\n",
        "url = 'https://baseball.yahoo.co.jp/npb/stats/batter?gameKindId=1'\n",
        "res = requests.get(url)\n",
        "content = res.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHglwuuGhjq6"
      },
      "source": [
        "content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmgqTTR4ntDQ"
      },
      "source": [
        "## htmlコードを見て、取得したいデータのタグを検証する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azdbXLJ5hu8Z"
      },
      "source": [
        "# table 要素を取得\n",
        "bs = BS(content, \"lxml\")  # parserの高速化 https://naruport.com/blog/2019/7/13/how-to-use-of-beautiful-soup-4/\n",
        "tables = bs.find_all(\"table\")\n",
        "n_tables = len(tables)\n",
        "print(n_tables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables"
      ],
      "metadata": {
        "id": "ede3IIgMzyGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke6F1jpxiXYh"
      },
      "source": [
        "#抽出したテーブルが複数ある場合\n",
        "if n_tables > 1:\n",
        "    for i in range(n_tables):\n",
        "        print(tables[i])            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCVYF_mLiQlt"
      },
      "source": [
        "table = tables[0]\n",
        "\n",
        "# table head 要素を取得 (存在する場合)\n",
        "thead = table.find(\"thead\")\n",
        "\n",
        "# thead が存在する場合\n",
        "if thead:\n",
        "    tr = thead.find(\"tr\")\n",
        "    ths = tr.find_all(\"th\")\n",
        "    columns = [th.text for th in ths]    # pandas.DataFrame を意識\n",
        "# thead が存在しない場合\n",
        "else:\n",
        "    columns = []\n",
        "\n",
        "columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7kmxCNQlPHP"
      },
      "source": [
        "# table body 要素を取得\n",
        "tbody = table.find(\"tbody\")\n",
        "\n",
        "# tr 要素を取得\n",
        "trs = tbody.find_all(\"tr\")\n",
        "\n",
        "# 出力したい行データ\n",
        "rows = [columns]\n",
        "\n",
        "# td (th) 要素の値を読み込む\n",
        "for tr in trs:\n",
        "    row = [td.text for td in tr.find_all([\"td\"])]\n",
        "    rows.append(row)\n",
        "\n",
        "rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64ivoDrGleFG"
      },
      "source": [
        "# データを書き込む\n",
        "import csv\n",
        "\n",
        "filepath = \"baseball_data.csv\"\n",
        "\n",
        "with open(filepath, \"w\") as f:\n",
        "    writer = csv.writer(f, lineterminator=\"\\n\")\n",
        "    writer.writerows(rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DzoVY9Zxb7V"
      },
      "source": [
        "**簡単な方法**\n",
        "\n",
        "pandas read_html で簡単にテーブル情報を取得できる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w8LD8Gv0OCD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://baseball.yahoo.co.jp/npb/stats/batter?gameKindId=1'\n",
        "\n",
        "dfs = pd.read_html(url, encoding='utf-8')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs"
      ],
      "metadata": {
        "id": "StuT_2jcynaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VATwyRjtuZYT"
      },
      "source": [
        "dfs.to_csv('baseball_data_pandas.csv', encoding='utf-8', index=False, header=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}