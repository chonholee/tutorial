{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chonholee/tutorial/blob/main/bigdata/BigDataII_11_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp2DI_WksXmG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/MyDrive/Lecture_BigData'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_suNgwIqJhr6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ9A14RsgJXy"
      },
      "source": [
        "# CNN (Convolutional Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1auJhoy9ocCv"
      },
      "outputs": [],
      "source": [
        "# (1) 手書き数字画像のデータセットをダウンロード・正規化\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "channel = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPoxrQqDJQFY"
      },
      "outputs": [],
      "source": [
        "# (2) 簡単なCNNモデルを構築してみる\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add( Conv2D(32, (3, 3), input_shape=(28, 28, channel), activation='relu') )      # 追加\n",
        "model.add( MaxPooling2D(pool_size=(2,2)) )              # 追加\n",
        "model.add( Conv2D(32, (3, 3), activation='relu') )      # 追加\n",
        "model.add( MaxPooling2D(pool_size=(2,2)) )              # 追加\n",
        "model.add( Flatten() )\n",
        "model.add( Dense(128, activation='relu') )\n",
        "model.add( Dropout(0.2) )\n",
        "model.add( Dense(num_classes, activation='softmax') )\n",
        "\n",
        "# モデルの構造を見てみる\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxZkzQEkqAxV"
      },
      "outputs": [],
      "source": [
        "# (3) モデルのコンパイル\n",
        "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# (4) モデルの学習開始\n",
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORUIxiMypaki"
      },
      "outputs": [],
      "source": [
        "# (5) モデルの評価\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7iTZ-VP4qnw"
      },
      "outputs": [],
      "source": [
        "# 保存\n",
        "model_filename = 'mymodel_cnn'\n",
        "model.save(model_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEQt0sM-iIA_"
      },
      "source": [
        "# cifar10 Dataset (一般カラー画像) の分類\n",
        "\n",
        "*runtimeの種類をGPUに変更することを勧めます。学習の処理が早くなります。*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwovlt85Kxqj"
      },
      "outputs": [],
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "# データをロードして、x_train, y_train, x_test, y_testを準備してください\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDQ28GTyi0Zl"
      },
      "outputs": [],
      "source": [
        "# データのサイズ（shape）、画像1枚のサイズ（縦横ピクセルサイズ）を確認してください\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOqtiBJbp9mI"
      },
      "outputs": [],
      "source": [
        "# RGB画像、R（レッド）,G（グリーン）,B（ブルー）の三つのチャンネルにそれぞれ0から255の値が入っています。\n",
        "# その値を255.0で割ることによって、R,G,Bに入っている値が0から1までになるようにしてください。\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M6BALUpjskj"
      },
      "outputs": [],
      "source": [
        "# 好きな画像を10枚、ラベルと一緒に表示させなさい。\n",
        "\n",
        "here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O54Ysb0pFq8"
      },
      "outputs": [],
      "source": [
        "# CNNモデルを定義しなさい\n",
        "#   基本的にはMNISTデータの演習で行ったCNNと同じ構造で試してみましょう。\n",
        "#   入力データのサイズとチャネル数、クラスの数を確認して修正\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGs4jmdY7c8Y"
      },
      "outputs": [],
      "source": [
        "# モデルのコンパイル\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E4nR4rRsOI9"
      },
      "outputs": [],
      "source": [
        "# モデルの学習\n",
        "#   epochs=5 で学習\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytf-TO2K7jl9"
      },
      "outputs": [],
      "source": [
        "# モデルの評価\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWdV8MI8rQs7"
      },
      "outputs": [],
      "source": [
        "# model.predict(...)、numpy.argmax(...) などを使って、test画像をいくつか分類してみてください。\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwR-c8dbroga"
      },
      "outputs": [],
      "source": [
        "# モデルを再学習\n",
        "#   epochs=10 で学習\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7cXtuaLsapF"
      },
      "outputs": [],
      "source": [
        "# モデルの評価\n",
        "# lossは下がってますか？accuracyはあがってますか？\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9KahNOCsb9h"
      },
      "outputs": [],
      "source": [
        "# 上で間違って分類されたtest画像をいくつか分類してみてください。\n",
        "\n",
        "here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rba8UzO_PVF"
      },
      "source": [
        "# 自前のデータセットを用意して、異なる分類モデルを学習させてみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "前準備\n",
        "\n",
        "* 学習データセット用のフォルダを用意する\n",
        "* 分類ラベルごとの**サブフォルダ**を用意する\n",
        "* 各サブフォルダに、画像を保存する\n",
        "\n",
        "今回は例として猫と犬の画像を分類する\n",
        "\n",
        "* 「Cat」「Dog」のサブフォルダを用意して画像を保存する"
      ],
      "metadata": {
        "id": "_e78oYnPp946"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"petimages-subset/\""
      ],
      "metadata": {
        "id": "3biHylJNpwzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-2nk5si_OXA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)\n",
        "train_dataset = image_dataset_from_directory(directory,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset='training',\n",
        "                                             seed=42)\n",
        "validation_dataset = image_dataset_from_directory(directory,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE,\n",
        "                                             validation_split=0.2,\n",
        "                                             subset='validation',\n",
        "                                             seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR9uNiPjAgS-"
      },
      "outputs": [],
      "source": [
        "class_names = train_dataset.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(\"{}: {}\".format(labels[i].numpy(), class_names[labels[i]]))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "kRVSzxil4SRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMCoOJRS2-OI"
      },
      "outputs": [],
      "source": [
        "# 正規化 (別の書き方)\n",
        "\n",
        "norm_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1/255.)\n",
        "\n",
        "norm_train_dataset = train_dataset.map(lambda x, y: (norm_layer(x), y))\n",
        "norm_val_dataset = validation_dataset.map(lambda x, y: (norm_layer(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKjaNTSEb6Z6"
      },
      "source": [
        "## VGG16 モデル\n",
        "\n",
        "imagenetをベースとしたCNNモデルの一種"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdNvCyxRH5s5"
      },
      "outputs": [],
      "source": [
        "# データの拡張Layerを定義\n",
        "\n",
        "# 学習データが少ない時、現状で用意できるデータセットからデータ数を増やす手段\n",
        "#    参照：https://www.codexa.net/data_augmentation_python_keras/\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDVFfmn4INjF"
      },
      "outputs": [],
      "source": [
        "#--- Layerの準備 ---\n",
        "\n",
        "IMG_SIZE = (32, 32, 3)\n",
        "\n",
        "# 入力の前処理として「データ拡張」を行う\n",
        "inputs = tf.keras.Input(shape=(None, None, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = tf.keras.layers.Lambda(lambda img: tf.image.resize(img, (IMG_SIZE[0], IMG_SIZE[1])))(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vty2GLN4e7eQ"
      },
      "outputs": [],
      "source": [
        "\"\"\" VGG16 \"\"\"\n",
        "x = tf.keras.layers.Lambda(tf.keras.applications.vgg16.preprocess_input)(x)\n",
        "\n",
        "base_model = tf.keras.applications.vgg16.VGG16(\n",
        "      input_shape=IMG_SIZE,\n",
        "      input_tensor=x,\n",
        "      include_top=False, \n",
        "      weights='imagenet'     \n",
        ")\n",
        "\n",
        "base_model.trainable = True # base model の重みを固定する場合\n",
        "\n",
        "# 全結合層出なくGlobal Average Pooling を使用することで計算量を減らせます\n",
        "GAP_layer = GlobalAveragePooling2D()\n",
        "\n",
        "# 最終層\n",
        "pred_layer = Dense(len(class_names), activation='softmax')\n",
        "\n",
        "#--- モデルの構築 ---\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    GAP_layer,\n",
        "    pred_layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJRqdNcXG2id",
        "outputId": "499c9149-84ab-447a-d012-8e9bcd3d7c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,715,714\n",
            "Trainable params: 14,715,714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpgXmorFAV_s"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlcHmcNMGs-Y"
      },
      "outputs": [],
      "source": [
        "# (3) モデルのコンパイル\n",
        "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# (4) モデルの学習開始\n",
        "model.fit(norm_train_dataset, validation_data=norm_val_dataset, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMz22Dl-Zo90"
      },
      "outputs": [],
      "source": [
        "# 保存\n",
        "model_filename = 'mymodel/vgg16'\n",
        "model.save_weights(model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl51UO1fZuHn",
        "outputId": "86e1cc21-35f5-44f9-c2f5-3efc01cf1324"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f20a2fc85e0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# 読み込み\n",
        "model.load_weights(model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAKjCp32Z__b"
      },
      "outputs": [],
      "source": [
        "# 再学習\n",
        "model.fit(norm_train_dataset, validation_data=norm_val_dataset, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlJk-_T5bjET"
      },
      "outputs": [],
      "source": [
        "# 保存\n",
        "model_filename = 'mymodel/vgg16'\n",
        "model.save_weights(model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpN5pr9BcN9g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "for images, labels in validation_dataset.take(1): # <--- テスト用にValidation画像を用いる\n",
        "\n",
        "    # テスト画像を一度に分類できる\n",
        "    imgs = tf.image.resize(images, (IMG_SIZE[0], IMG_SIZE[1]))\n",
        "    outputs = model.predict(imgs) # softmax の結果（信頼度）\n",
        "    predicted = np.argmax(outputs, 1)\n",
        "    print(outputs)\n",
        "    print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 結果を一枚ずつ確認\n",
        "for i in range(len(outputs)):\n",
        "    print('test', i, end=':')\n",
        "    print(' predicted class label', class_names[predicted[i]], end=',')\n",
        "    print(' true class label', class_names[labels[i]])"
      ],
      "metadata": {
        "id": "qhwOaxxCAL-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSWnrik9OPn_"
      },
      "source": [
        "## MobileNet V2\n",
        "\n",
        "デバイスでも動くようにパラメータの数を減らして最適化したモデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFQ6MgvhOPJO"
      },
      "outputs": [],
      "source": [
        "#--- Layerの準備 ---\n",
        "num_classes = 2\n",
        "\n",
        "IMG_SIZE = (96, 96, 3)\n",
        "\n",
        "# 入力の前処理\n",
        "inputs = tf.keras.Input(shape=(None, None, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = tf.keras.layers.Lambda(lambda img: tf.image.resize(img, (IMG_SIZE[0], IMG_SIZE[1])))(x)\n",
        "x = tf.keras.layers.Lambda(tf.keras.applications.mobilenet_v2.preprocess_input)(x)\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=IMG_SIZE,\n",
        "    input_tensor=x,\n",
        "    include_top = False,  #False にすることで出力層は読み込みません\n",
        "    weights='imagenet')\n",
        "\n",
        "base_model.trainable = True # base model の重みを固定する場合\n",
        "\n",
        "# 全結合層出なくGlobal Average Pooling を使用することで計算量を減らせます\n",
        "GAP_layer = GlobalAveragePooling2D()\n",
        "\n",
        "# 最終層\n",
        "pred_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "#--- モデルの構築 ---\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    GAP_layer,\n",
        "    pred_layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYzt0CgEDoJv"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u93rt_3XOcoq"
      },
      "outputs": [],
      "source": [
        "# petimages用\n",
        "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(norm_train_dataset, validation_data=norm_val_dataset, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U7A_B1bVOCp"
      },
      "outputs": [],
      "source": [
        "# 保存\n",
        "model.save_weights(\"mymodel/mobilenetv2-petimage\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHCWu5-4mRUn"
      },
      "outputs": [],
      "source": [
        "# cifar10用\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "num_classes = 10\n",
        "\n",
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_lLARV0AueX"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"mymodel/mobilenetv2-cifar10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McNlcKGRnZlH"
      },
      "source": [
        "## ResNet50\n",
        "\n",
        "モデルの層をより深く\n",
        "\n",
        "参照：https://deepage.net/deep_learning/2016/11/30/resnet.html\n",
        "\n",
        "※※※\n",
        "\n",
        "モデル構築の部分を少し違った描き方で書いています。\n",
        "\n",
        "VGGとMobileNetのサンプルでは、層を定義して最後にまとめていますが\n",
        "\n",
        "以下ResNetのサンプルでは、層を定義すると同時にモデルの構築を行っています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95-aSRK3nSXI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "IMG_SIZE = (224, 224, 3)\n",
        "\n",
        "def get_model():\n",
        "    base_model_res50 = ResNet50(\n",
        "         include_top=True, \n",
        "         input_shape=IMG_SIZE,\n",
        "         weights='imagenet')\n",
        "    # take the last global average pooling with fewer parameters\n",
        "    x = base_model_res50.layers[-2].output\n",
        "    \n",
        "    x = Dense(2048)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(.5)(x)\n",
        "    \n",
        "    x = Dense(2048)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(.5)(x)\n",
        "    \n",
        "    x = Dense(10)(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "\n",
        "    model = Model(base_model_res50.input, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwNA-6QSEi5m"
      },
      "outputs": [],
      "source": [
        "model = get_model()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf7zG4wanq2M"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit(norm_train_dataset, validation_data=norm_val_dataset, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwMQx5j37t-X"
      },
      "source": [
        "# 補足（時間の関係で講義内に説明しきればかった内容）\n",
        "\n",
        "オンラインの資料などを見ながら勉強してみてください。\n",
        "\n",
        "*   **softmax**\n",
        "*   **one-hot encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fdV1MshjMn5"
      },
      "source": [
        "今回の演習や課題で扱ったデータセットのラベルはカテゴリーデータ（離散値）です。\n",
        "\n",
        "*   mnist dataでは、０～９までの数字\n",
        "*   cifar10 dataでは、物体の名前に対応した0～９までの数字\n",
        "\n",
        "例えば、y_train[0] には（x_train[0]に対応した）１つの値が格納されています。\n",
        "\n",
        "ですが、モデルの最終層のニューロンの数はクラスの数（10個）となっています。\n",
        "\n",
        "```\n",
        "model.add( tf.keras.layers.Dense(10, activation='softmax') )\n",
        "```\n",
        "\n",
        "講義で損失関数（真値と計算値の誤差）の話をしましたが、現在真値は1個、計算値は10個の値があるので単純に引き算（損失関数）を計算できません。\n",
        "\n",
        "実は\n",
        "```\n",
        "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "```\n",
        "の「sparse categorical crossentoropy」内で上手く計算してくれています。\n",
        "\n",
        "一般的には、真値の数を最終層の数（分類するクラスの数）と合わせるための処理をします。\n",
        "\n",
        "その一つが 「**one-hot encodings**」 と呼ばれるものです。\n",
        "\n",
        "例えば\n",
        "\n",
        "2 (bird) は [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "7 (horse) は [0,0,0,0,0,0,0,1,0,0]\n",
        "\n",
        "とエンコーディング変換する事を言います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6MrIOPuiawh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(y_train[0]) # 確認\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(y_train[0]) # 確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1fNueYy_67v"
      },
      "source": [
        "クラスラベル（y_train と y_test）を one-hot として扱う場合は、「categorical_crossentropy」というlossを使います。\n",
        "\n",
        "試してみてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPC7890vURGk"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AHvLb2vV0eO"
      },
      "outputs": [],
      "source": [
        "a = [[('n04592741', 'wing', 0.9714641), ('n02690373', 'airliner', 0.025861548), ('n04266014', 'space_shuttle', 0.0013809769)], [('n03899768', 'patio', 0.51726824), ('n03028079', 'church', 0.25273263), ('n04005630', 'prison', 0.046136115)], [('n02129604', 'tiger', 0.767321), ('n02123159', 'tiger_cat', 0.22703454), ('n02391049', 'zebra', 0.004188579)], [('n02504013', 'Indian_elephant', 0.7616036), ('n01871265', 'tusker', 0.21664836), ('n02504458', 'African_elephant', 0.021731125)], [('n11939491', 'daisy', 0.26833987), ('n01828970', 'bee_eater', 0.14348479), ('n03876231', 'paintbrush', 0.08295382)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkDkYpwkV3tM",
        "outputId": "05c9848c-3499-46f8-ebac-6459d6b0a314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 [('n04592741', 'wing', 0.9714641), ('n02690373', 'airliner', 0.025861548), ('n04266014', 'space_shuttle', 0.0013809769)]\n",
            "1 [('n03899768', 'patio', 0.51726824), ('n03028079', 'church', 0.25273263), ('n04005630', 'prison', 0.046136115)]\n",
            "2 [('n02129604', 'tiger', 0.767321), ('n02123159', 'tiger_cat', 0.22703454), ('n02391049', 'zebra', 0.004188579)]\n",
            "3 [('n02504013', 'Indian_elephant', 0.7616036), ('n01871265', 'tusker', 0.21664836), ('n02504458', 'African_elephant', 0.021731125)]\n",
            "4 [('n11939491', 'daisy', 0.26833987), ('n01828970', 'bee_eater', 0.14348479), ('n03876231', 'paintbrush', 0.08295382)]\n"
          ]
        }
      ],
      "source": [
        "for i, labels in enumerate(a):\n",
        "  print(i, labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8qdUCIBH3skkedctwPDMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}