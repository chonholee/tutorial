{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigDataII_11_CNN3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0VsTH5oKg9ailKmCiJN5B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chonholee/tutorial/blob/main/bigdata/BigDataII_11_CNN3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/MyDrive/Lecture_BigData'"
      ],
      "metadata": {
        "id": "Zp2DI_WksXmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習済みモデルで推論"
      ],
      "metadata": {
        "id": "kwd4Hqh4ZzE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions\n",
        "\n",
        "import numpy as np\n",
        "import os, json, csv\n",
        "\n",
        "image_size = 224\n",
        "\n",
        "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
        "    imgs = [image.load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n",
        "    img_array = np.array([image.img_to_array(img) for img in imgs])\n",
        "    output = preprocess_input(img_array)\n",
        "    return(output)\n",
        "\n",
        "\"\"\" モデルの読み込み \"\"\"\n",
        "model = ResNet50(weights='imagenet') # <--- 別のモデルで検証できる\n",
        "# model.load_weights(model_filename) # <--- 学習済みモデルの重み\n",
        "\n",
        "\n",
        "\"\"\" テストデータの読み込み \"\"\"\n",
        "image_paths = 'dataset/test-images'\n",
        "image_paths = [os.path.join(image_paths,filename) for filename in sorted(os.listdir(image_paths))]\n",
        "test_data = read_and_prep_images(image_paths)\n",
        "\n",
        "\"\"\" 推論 \"\"\"\n",
        "preds = model.predict(test_data)\n",
        "\n",
        "\"\"\" Top3 書き込み \"\"\"\n",
        "#predicted = decode_predictions(preds, top=3, class_list_path='dataset/imagenet_class_index.json')\n",
        "predicted = decode_predictions(preds, top=3)\n",
        "\n",
        "with open(\"results.csv\", \"w\") as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow([\"IMAGE_PATH\", \"TOP1\", \"TOP2\", \"TOP3\"])\n",
        "  for i, labels in enumerate(predicted):\n",
        "    row = [image_paths[i], labels[0][1], labels[1][1], labels[2][1]]\n",
        "    writer.writerow(row)\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "_suNgwIqJhr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 物体検出"
      ],
      "metadata": {
        "id": "i1CxzucPYy11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "from google.colab.patches import cv2_imshow # incompatible with Jupyter notebook\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.densenet import preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "\n",
        "model = DenseNet121(weights='imagenet')\n",
        "\n",
        "def run(img_str):\n",
        "    #decode to image\n",
        "    decimg = base64.b64decode(img_str.split(',')[1], validate=True)\n",
        "    decimg = Image.open(BytesIO(decimg))\n",
        "    decimg = np.array(decimg, dtype=np.uint8); \n",
        "    decimg = cv2.cvtColor(decimg, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    #############your process###############\n",
        "    # DenseNet121画像判定\n",
        "    resize_frame = cv2.resize(decimg, (300, 224))           # 640x480 -> 300x224(4:3)に画像リサイズ\n",
        "    trim_x, trim_y = int((300-224)/2), 0                    # 判定用に224x224へトリミング\n",
        "    trim_h, trim_w = 224, 224\n",
        "    trim_frame = resize_frame[trim_y : (trim_y + trim_h), trim_x : (trim_x + trim_w)]\n",
        "    x = image.img_to_array(trim_frame)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)                                # 画像AI判定\n",
        "\n",
        "    # 認識物体名, 認識率 表示用\n",
        "    TXT1 = \"[DenseNet121 predict]\"\n",
        "    TXT2 = \"TOP1 :\" + decode_predictions(preds, top=3)[0][0][1] + \" : \" + str(int(decode_predictions(preds, top=3)[0][0][2] * 100)) + \"%\"\n",
        "    TXT3 = \"TOP2 :\" + decode_predictions(preds, top=3)[0][1][1] + \" : \" + str(int(decode_predictions(preds, top=3)[0][1][2] * 100)) + \"%\"\n",
        "    TXT4 = \"TOP3 :\" + decode_predictions(preds, top=3)[0][2][1] + \" : \" + str(int(decode_predictions(preds, top=3)[0][2][2] * 100)) + \"%\"\n",
        "\n",
        "    img = Image.fromarray(trim_frame)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    draw.text((15, 10), TXT1, fill=(255, 255, 255, 0))\n",
        "    draw.text((15, 30), TXT2, fill=(255, 255, 255, 0))\n",
        "    draw.text((15, 50), TXT3, fill=(255, 255, 255, 0))\n",
        "    draw.text((15, 70), TXT4, fill=(255, 255, 255, 0))\n",
        "    img = np.array(img)\n",
        "#   cv2_imshow(img)\n",
        "    out_img = cv2.resize(img, (224*3, 224*3))               # 拡大表示\n",
        "    #############your process###############\n",
        "\n",
        "    #encode to string\n",
        "    _, encimg = cv2.imencode(\".jpg\", out_img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
        "    img_str = encimg.tostring()\n",
        "    img_str = \"data:image/jpeg;base64,\" + base64.b64encode(img_str).decode('utf-8')\n",
        "    return IPython.display.JSON({'img_str': img_str})\n",
        "\n",
        "output.register_callback('notebook.run', run)"
      ],
      "metadata": {
        "id": "F2R3jArngZNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "def use_cam(quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function useCam(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "      //video element\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'None';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      //canvas for display. frame rate is depending on display size and jpeg quality.\n",
        "      display_size = 640 \n",
        "      const src_canvas = document.createElement('canvas');\n",
        "      src_canvas.width  = display_size;\n",
        "      src_canvas.height = display_size * video.videoHeight / video.videoWidth;\n",
        "      const src_canvasCtx = src_canvas.getContext('2d');\n",
        "      src_canvasCtx.translate(src_canvas.width, 0);\n",
        "      src_canvasCtx.scale(-1, 1);\n",
        "      div.appendChild(src_canvas);\n",
        "\n",
        "      const dst_canvas = document.createElement('canvas');\n",
        "      dst_canvas.width  = src_canvas.width;\n",
        "      dst_canvas.height = src_canvas.height;\n",
        "      const dst_canvasCtx = dst_canvas.getContext('2d');\n",
        "      div.appendChild(dst_canvas);\n",
        "\n",
        "      //exit button\n",
        "      const btn_div = document.createElement('div');\n",
        "      document.body.appendChild(btn_div);\n",
        "      const exit_btn = document.createElement('button');\n",
        "      exit_btn.textContent = 'Exit';\n",
        "      var exit_flg = true\n",
        "      exit_btn.onclick = function() {exit_flg = false};\n",
        "      btn_div.appendChild(exit_btn);\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      var send_num = 0\n",
        "      // loop\n",
        "      _canvasUpdate();\n",
        "      async function _canvasUpdate() {\n",
        "            src_canvasCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight, 0, 0, src_canvas.width, src_canvas.height);     \n",
        "            if (send_num<1){\n",
        "                send_num += 1\n",
        "                const img = src_canvas.toDataURL('image/jpeg', quality);\n",
        "                const result = google.colab.kernel.invokeFunction('notebook.run', [img], {});\n",
        "                result.then(function(value) {\n",
        "                    parse = JSON.parse(JSON.stringify(value))[\"data\"]\n",
        "                    parse = JSON.parse(JSON.stringify(parse))[\"application/json\"]\n",
        "                    parse = JSON.parse(JSON.stringify(parse))[\"img_str\"]\n",
        "                    var image = new Image()\n",
        "                    image.src = parse;\n",
        "                    image.onload = function(){dst_canvasCtx.drawImage(image, 0, 0)}\n",
        "                    send_num -= 1\n",
        "                })\n",
        "            }\n",
        "            if (exit_flg){\n",
        "                requestAnimationFrame(_canvasUpdate);   \n",
        "            }else{\n",
        "                stream.getVideoTracks()[0].stop();\n",
        "            }\n",
        "      };\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('useCam({})'.format(quality))"
      ],
      "metadata": {
        "id": "SI2N3AXLgamE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cam()"
      ],
      "metadata": {
        "id": "wWGV0jG7glKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO v5 モデル"
      ],
      "metadata": {
        "id": "cxyFI3srIWHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR = '/content/tmp'\n",
        "!mkdir $WORKING_DIR\n",
        "%cd $WORKING_DIR"
      ],
      "metadata": {
        "id": "JUFMYQ4LgqKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "GxPP6S-KIZh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5/\n",
        "!pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "w5LU5VZHIpq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
        "!unzip coco128.zip"
      ],
      "metadata": {
        "id": "LFVvn7kTIfIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 300 --data coco128.yaml --weights yolov5x.pt"
      ],
      "metadata": {
        "id": "Ag8Gw_LLIktv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source data/images --weights yolov5x.pt --conf 0.50"
      ],
      "metadata": {
        "id": "v7pqAuOPJsTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "images = glob.glob(\"runs/detect/exp8/*.jpg\")\n",
        "for i in range(len(images)):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  img = image.load_img(images[i])\n",
        "  plt.imshow(img)\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "29S6jfJYNAaC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}