{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TgOsX2LUi335",
        "t5eAMtxvq1BV"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chonholee/tutorial/blob/main/bigdata/BigdataII_11_CustomDataset_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd \"/content/drive/MyDrive/Lecture_BigData\""
      ],
      "metadata": {
        "id": "mS0MratkZk8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LF5_Ea6qRFQ"
      },
      "source": [
        "# 第11回 (Part2) カスタムデータによる画像認識"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 事前準備"
      ],
      "metadata": {
        "id": "TgOsX2LUi335"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmvqz-691Wym"
      },
      "source": [
        "# 必要ライブラリ・コマンドの導入\n",
        "\n",
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1\n",
        "w = !apt install tree\n",
        "print(w[-2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBjRX49eqRFd"
      },
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJy-mzVHqRFi"
      },
      "source": [
        "# PyTorch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "from torch import tensor\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.datasets as datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx2Zkbou1Nfc"
      },
      "source": [
        "# warning表示off\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqa0F-rK1WZu"
      },
      "source": [
        "# GPUチェック\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLJx4mjqGsj1"
      },
      "source": [
        "# 共通関数のダウンロード\n",
        "!git clone https://github.com/makaishi2/pythonlibs.git\n",
        "\n",
        "# 共通関数のロード\n",
        "from pythonlibs.torch_lib1 import *\n",
        "\n",
        "# 共通関数の存在チェック\n",
        "print(README)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 transformsを用いたデータ拡張\n",
        "\n",
        "参照：https://pystyle.info/pytorch-list-of-transforms/\n",
        "\n",
        "データ拡張（Data Augmentation）は、元のデータセットから新しいトレーニングデータを生成する方法で、主に以下の目的で用いられる.\n",
        "\n",
        "1. **多様性を増やす**：限られたデータセットから、多様なパターンや変化を持つデータを生成することで、モデルの汎化性能を向上させる．\n",
        "   \n",
        "2. **過学習を防ぐ**：モデルがトレーニングデータに過度に適応することを防ぎ、新しいデータに対する汎化性能を高める．\n",
        "\n",
        "画像、音声、テキストなどのデータ形式に対して様々な手法がある．\n",
        "例えば画像の場合\n",
        "\n",
        "- **反転（フリップ）**: 画像を水平または垂直に反転させる。\n",
        "- **回転**: 画像を一定の角度で回転させる。\n",
        "- **ズーム**: 画像の一部を拡大または縮小する。\n",
        "- **クロッピング**: 画像の一部を切り取る。\n",
        "- **色の変更**: 画像の色合いや明るさを変える。\n",
        "- **ノイズの追加**: 画像にノイズを追加する。\n",
        "\n",
        "これらの手法を使用して、元のデータを変換し、新しいデータを生成することで、データセットのサイズを増やしたり、さまざまなバリエーションを持つデータを作成する．これにより、機械学習モデルがより多くのパターンを学習し、一般化能力を向上させることが期待される．\n",
        "\n"
      ],
      "metadata": {
        "id": "t5eAMtxvq1BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "グレースケール"
      ],
      "metadata": {
        "id": "2aC4MjyFtryk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils import data as data\n",
        "from torchvision import transforms as transforms\n",
        "\n",
        "img = Image.open(\"sample.jpg\")\n",
        "display(img)\n",
        "\n",
        "# グレースケール変換を行う Transforms\n",
        "transform = transforms.Grayscale()\n",
        "\n",
        "# 関数呼び出しで変換を行う\n",
        "img = transform(img)\n",
        "img"
      ],
      "metadata": {
        "id": "bbJv_M_aq_mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "中心を切り抜く\n",
        "\n",
        "* size – 切り抜く大きさ\n",
        " * int – 幅 size、高さ size となるように切り抜く\n",
        " * 2-ints sequence – 幅 size[0]、高さ size[1] となるように切り抜\n"
      ],
      "metadata": {
        "id": "0yfXzXuyrZb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"sample.jpg\")\n",
        "transform = transforms.CenterCrop(150)\n",
        "\n",
        "img = transform(img)\n",
        "img"
      ],
      "metadata": {
        "id": "C3EKuTnurM17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "同じ大きさの5枚の画像をタイル上に並べる。"
      ],
      "metadata": {
        "id": "ef8UL2tVsT6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tile_imgs(imgs, n_cols=3):\n",
        "    \"\"\"同じ大きさの複数枚の画像をタイル上に並べる。\n",
        "    \"\"\"\n",
        "    n_rows = int(np.ceil(len(imgs) / n_cols))\n",
        "    w, h = imgs[0].size\n",
        "\n",
        "    # 結合後の画像\n",
        "    concat_img = Image.new(\"RGB\", (w * n_cols, h * n_rows))\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        row, col = i % n_cols, i // n_cols\n",
        "        concat_img.paste(img, (w * row, h * col))\n",
        "\n",
        "    return concat_img\n",
        "\n",
        "img = Image.open(\"sample.jpg\")\n",
        "transform = transforms.FiveCrop(150)\n",
        "\n",
        "imgs = transform(img)\n",
        "tile_imgs(imgs)"
      ],
      "metadata": {
        "id": "kLvqVMS_r8hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ランダムクロップ（ランダムに切り抜く）"
      ],
      "metadata": {
        "id": "hkE7JwzEsyeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "img = Image.open(\"sample.jpg\")\n",
        "random.seed(0)\n",
        "\n",
        "transform = transforms.RandomCrop(150)\n",
        "display(transform(img))\n",
        "\n",
        "transform = transforms.RandomCrop((100, 200))\n",
        "display(transform(img))\n",
        "\n",
        "transform = transforms.RandomCrop(250, pad_if_needed=True)\n",
        "display(transform(img))"
      ],
      "metadata": {
        "id": "ssIpOsgxsukq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "リサイズ"
      ],
      "metadata": {
        "id": "KJueITTbtwgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"sample.jpg\")\n",
        "\n",
        "transform = transforms.Resize(150)\n",
        "display(transform(img))\n",
        "\n",
        "transform = transforms.Resize((150, 150))\n",
        "display(transform(img))"
      ],
      "metadata": {
        "id": "tdKL2GLLsA0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ガウシアンフィルタを行う Transform です。"
      ],
      "metadata": {
        "id": "oTMXxefLsm_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"sample.jpg\")\n",
        "\n",
        "transform = transforms.GaussianBlur(kernel_size=5)\n",
        "display(transform(img))"
      ],
      "metadata": {
        "id": "UbTpystusbHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "反転"
      ],
      "metadata": {
        "id": "WUMsWrWrs_q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"sample.jpg\")\n",
        "random.seed(0)\n",
        "\n",
        "transform = transforms.RandomHorizontalFlip(0.9)\n",
        "display(transform(img))"
      ],
      "metadata": {
        "id": "tPMxIvJysodV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"sample.jpg\")\n",
        "random.seed(0)\n",
        "\n",
        "transform = transforms.RandomVerticalFlip(0.9)\n",
        "display(transform(img))"
      ],
      "metadata": {
        "id": "xMfmu1vGs_GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "回転"
      ],
      "metadata": {
        "id": "lab1WsTMtH-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"sample.jpg\")\n",
        "random.seed(0)\n",
        "\n",
        "transform = transforms.RandomRotation(degrees=15)\n",
        "\n",
        "imgs = [transform(img) for _ in range(6)]\n",
        "tile_imgs(imgs)"
      ],
      "metadata": {
        "id": "MM43xkOrtBGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compose**\n",
        "\n",
        "Compose を使用すると、複数の Transform を連続して行う Transform を作成できます。画像を読み込む際にリサイズや標準化など一連の処理を行いたい場合に便利です。\n",
        "\n",
        "(256, 256) にリサイズする\n",
        "画像の中心を (224, 224) で切り抜く\n",
        "PIL Image をテンソルに変換する"
      ],
      "metadata": {
        "id": "XEQLUFR1tglE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(\"sample.jpg\")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(256),\n",
        "     transforms.CenterCrop(224),\n",
        "     transforms.ToTensor()]\n",
        ")\n",
        "\n",
        "# 関数呼び出しで変換を行う\n",
        "img = transform(img)\n",
        "print(type(img), img.shape)"
      ],
      "metadata": {
        "id": "0UnvjKjStIqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obUglB5x18Lk"
      },
      "source": [
        "## 2 DataLoaderの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4HwQvQ-BCqI"
      },
      "source": [
        "### データダウンロード・解凍\n",
        "\n",
        "シベリアンハスキーとオオカミの画像を利用  \n",
        "ダウンロード元  \n",
        "https://pixabay.com/ja/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS7hQ-hwLssE"
      },
      "source": [
        "# データダウンロード\n",
        "w = !wget https://github.com/makaishi2/pythonlibs/raw/main/images/dog_wolf.zip\n",
        "print(w[-2])\n",
        "\n",
        "# 解凍\n",
        "!unzip dog_wolf.zip | tail -n 1\n",
        "\n",
        "# 解凍結果のツリー表示\n",
        "!tree dog_wolf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9SqXhI2VEI4"
      },
      "source": [
        "### データ拡張・Transforms定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RLUFj7RLssE"
      },
      "source": [
        "# 検証データ用 : 正規化のみ実施\n",
        "test_transform = transforms.Compose([\n",
        "    ***here *** # リサイズ\n",
        "    ***here *** # クロップ\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "])\n",
        "\n",
        "# 訓練データ用: 正規化に追加で反転とRandomErasingを実施 ← より多様な画像を用いて学習させるねらい\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    ***here *** # リサイズ\n",
        "    ***here *** # クロップ\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc2t3uIHdSaw"
      },
      "source": [
        "### データセット定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsaX1qNQ4HLf"
      },
      "source": [
        "# データセット定義\n",
        "data_dir = 'dog_wolf'\n",
        "\n",
        "import os\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "classes = ['dog', 'wolf']\n",
        "\n",
        "train_data = datasets.ImageFolder( ***here *** ) # 学習用\n",
        "test_data = datasets.ImageFolder( ***here *** )  # 検証用"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sz6Hcv7B9Ln"
      },
      "source": [
        "# データ件数確認\n",
        "\n",
        "print(f'学習データ: {len(train_data)}件')\n",
        "print(f'検証データ: {len(test_data)}件')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW67cCTEdXTd"
      },
      "source": [
        "### DataLoader定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiihQJiBdapk"
      },
      "source": [
        "batch_size = 5\n",
        "# 学習データ\n",
        "train_loader = DataLoader( ***here *** )\n",
        "\n",
        "# 検証データ\n",
        "test_loader = DataLoader( ***here *** )\n",
        "\n",
        "# イメージ表示用\n",
        "train_data2 = datasets.ImageFolder(train_dir, transform=test_transform)\n",
        "train_loader2 = DataLoader(train_data2, batch_size=40, shuffle=False)\n",
        "test_loader2 = DataLoader(test_data, batch_size=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58xpmTt-Vkxf"
      },
      "source": [
        "### イメージ表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et00TY8ZVn6Q"
      },
      "source": [
        "# 訓練用データ(４0件)\n",
        "show_images_labels(train_loader2, classes, None, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYH_8XQbVoEY"
      },
      "source": [
        "# 検証用データ(10件)\n",
        "torch_seed()\n",
        "show_images_labels(test_loader2, classes, None, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 モデル"
      ],
      "metadata": {
        "id": "sZkZuGZmcowy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 MLP (Multi Layer Perceptron)"
      ],
      "metadata": {
        "id": "-YB3ldOZnmWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net (nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(224 * 224  * 3, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, len(classes))\n",
        "        self.dropout1 = nn.Dropout2d(0.2)\n",
        "        self.dropout2 = nn.Dropout2d(0.2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        return self.relu(self.fc3(x))\n",
        "\n",
        "net = Net()\n",
        "net.cuda()  # GPU対応\n",
        "print(net)"
      ],
      "metadata": {
        "id": "9hUZ0dfplJdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習の定義"
      ],
      "metadata": {
        "id": "XbyK3pM2n7hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 乱数初期化\n",
        "torch_seed()\n",
        "\n",
        "# AdaptiveAvgPool2d関数の取り外し\n",
        "net.avgpool = nn.Identity()\n",
        "\n",
        "# GPUの利用\n",
        "net = net.to(device)\n",
        "\n",
        "lr = 0.001\n",
        "# 損失関数定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数定義\n",
        "# パラメータ修正の対象を最終ノードに限定\n",
        "optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9)\n",
        "\n",
        "# historyファイルも同時に初期化する\n",
        "history = np.zeros((0, 5))"
      ],
      "metadata": {
        "id": "cROVm3BFnQ_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習の実行\n",
        "\n",
        "※ fit関数を利用する（学習の実装は省略）"
      ],
      "metadata": {
        "id": "VMaD6xT1n-0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "history = fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)"
      ],
      "metadata": {
        "id": "hlwQf09wnRnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果表示"
      ],
      "metadata": {
        "id": "nkcojeyUoFQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_history(history)"
      ],
      "metadata": {
        "id": "KWrv9XvKnUKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "テストデータの分類結果表示"
      ],
      "metadata": {
        "id": "fNLjvfFvoP5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_seed()\n",
        "show_images_labels(test_loader2, classes, net, device)"
      ],
      "metadata": {
        "id": "BvDrKzdloSJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 CNN (Convolutional Neural Network）"
      ],
      "metadata": {
        "id": "EpQEATMgoTDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 5)  # 畳み込み層:(入力チャンネル数, フィルタ数、フィルタサイズ)\n",
        "        self.relu = nn.ReLU()  # ReLU\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # プーリング層:（領域のサイズ, 領域の間隔）\n",
        "        self.conv2 = nn.Conv2d(8, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*53*53, 256)  # 全結合層\n",
        "        self.dropout = nn.Dropout(p=0.5)  # ドロップアウト:(p=ドロップアウト率)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        #x = x.view(-1, 16*5*5)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "net = Net()\n",
        "net.cuda()  # GPU対応\n",
        "print(net)"
      ],
      "metadata": {
        "id": "SYqkM7-rcoCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習の定義"
      ],
      "metadata": {
        "id": "r7xCyQUcovv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 乱数初期化\n",
        "torch_seed()\n",
        "\n",
        "# AdaptiveAvgPool2d関数の取り外し\n",
        "net.avgpool = nn.Identity()\n",
        "\n",
        "# GPUの利用\n",
        "net = net.to(device)\n",
        "\n",
        "lr = 0.001\n",
        "# 損失関数定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数定義\n",
        "# パラメータ修正の対象を最終ノードに限定\n",
        "optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9)\n",
        "\n",
        "# historyファイルも同時に初期化する\n",
        "history = np.zeros((0, 5))"
      ],
      "metadata": {
        "id": "xZgTP_Q5dpKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習の実行"
      ],
      "metadata": {
        "id": "9o_XZ6xUozH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "history = fit(net, optimizer, criterion, num_epochs,\n",
        "          train_loader, test_loader, device, history)"
      ],
      "metadata": {
        "id": "-RA4RfF0gCMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果表示"
      ],
      "metadata": {
        "id": "7HO10ZBmo1aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_history(history)"
      ],
      "metadata": {
        "id": "rl_nkVa4kT4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "テストデータの分類結果表示"
      ],
      "metadata": {
        "id": "-sBtMKfkpAoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_seed()\n",
        "show_images_labels(test_loader2, classes, net, device)"
      ],
      "metadata": {
        "id": "a_05UKpxkTrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEnkwdHid3rC"
      },
      "source": [
        "### 3.3 学習済みモデルを活用 (転移学習)\n",
        "\n",
        "使用可能なモデルのリンク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VTSEJZz7XEz"
      },
      "source": [
        "# 学習済みモデルの読み込み\n",
        "from torchvision import models\n",
        "\n",
        "net = models.vgg19_bn(pretrained = True) # VGG19\n",
        "\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 乱数初期化\n",
        "torch_seed()\n",
        "\n",
        "# 最終ノードの出力を2に変更する\n",
        "in_features = net.classifier[6].in_features\n",
        "net.classifier[6] = nn.Linear(in_features, 2)\n",
        "\n",
        "# AdaptiveAvgPool2d関数の取り外し\n",
        "net.avgpool = nn.Identity()\n",
        "\n",
        "# GPUの利用\n",
        "net = net.to(device)\n",
        "\n",
        "lr = 0.001\n",
        "# 損失関数定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数定義\n",
        "# パラメータ修正の対象を最終ノードに限定\n",
        "optimizer = optim.SGD(net.classifier[6].parameters(),lr=lr,momentum=0.9)\n",
        "\n",
        "# historyファイルも同時に初期化する\n",
        "history = np.zeros((0, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzdy_JX8Knc-"
      },
      "source": [
        "# 学習の実行\n",
        "\n",
        "# 結果表示\n",
        "\n",
        "# テストデータの分類結果表示"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlHS2MHb2qer"
      },
      "source": [
        "## 演習１：その他のサンプルデータ\n",
        "\n",
        "ハチとアリの画像データセット"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-utQupbe6dYb"
      },
      "source": [
        "# サンプルデータのダウンロード\n",
        "w = !wget -nc https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "\n",
        "# 結果確認\n",
        "print(w[-2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpWlbLEiwX1e"
      },
      "source": [
        "# データ解凍\n",
        "w = !unzip -o hymenoptera_data.zip\n",
        "\n",
        "# 結果確認\n",
        "print(w[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PieDzc7gLsr_"
      },
      "source": [
        "# 解凍ファイルのtree表示\n",
        "!tree hymenoptera_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 演習２：自前のデータセット\n",
        "\n",
        "datasetのフォルダの中に、trainとtestフォルダを作成し、それぞれのフォルダに画像を用意する"
      ],
      "metadata": {
        "id": "wEM01mnRqknS"
      }
    }
  ]
}