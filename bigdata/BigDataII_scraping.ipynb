{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigDataII_scraping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDZ+E+QYcDncHmTVTI9nvJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chonholee/tutorial/blob/main/bigdata/BigDataII_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-Dn2B8rWdeq"
      },
      "source": [
        "# いつものDriveマウント\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/MyDrive/Lecture_BigData'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5DXrXCdlgx6"
      },
      "source": [
        "# スクレイピング\n",
        "\n",
        "# 演習１"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tvr549NWmGS"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1RYzEP_Q2tT"
      },
      "source": [
        "url = 'https://chonholee.github.io/tutorial/index.html'\n",
        "response = requests.get(url)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6crPnBgoX8Vz"
      },
      "source": [
        "# https://developer.mozilla.org/ja/docs/Web/HTTP/Status\n",
        "\n",
        "response.status_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Dian5jX_X6"
      },
      "source": [
        "response.encoding #文字コード"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS8OgiUzYC6e"
      },
      "source": [
        "response.content #取得した内容"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WysbcC2bYKN5"
      },
      "source": [
        "soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJTM9ltJPm6s"
      },
      "source": [
        "soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wnn2f-mYOzB"
      },
      "source": [
        "soup.title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0me6DdcYU4C"
      },
      "source": [
        "soup.title.string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc3UEV7djYQx"
      },
      "source": [
        "### HTML要素を取得する\n",
        "### find_all() や select() などの使い方\n",
        "https://gammasoft.jp/blog/difference-find-and-select-in-beautiful-soup-of-python/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTD0GTIYRCuZ"
      },
      "source": [
        "# ホームページのソースを見ながら、取得したい情報のタグを記入\n",
        "\n",
        "result = soup.find_all(\"body\")\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLLhu_fXkHNc"
      },
      "source": [
        "# ページ内の全てのリンクの名前とアドレスとを抽出する\n",
        "\n",
        "for r in soup.find_all(\"a\"):\n",
        "    print(r.string, r['href'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCL3uOORpRtE"
      },
      "source": [
        "# ページ内の全てのリンクアドレスをリストにする\n",
        "\n",
        "links = [x.get('href') for x in soup.find_all('a')]\n",
        "print(links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caKA6O4ZklD1"
      },
      "source": [
        "# 演習2　テーブル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXRmUzq8kkfu"
      },
      "source": [
        "url = 'https://chonholee.github.io/tutorial/bigdata/test-table.html'\n",
        "r = requests.get(url)\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVqdv3Srk9hR"
      },
      "source": [
        "result = soup.find_all('th')\n",
        "for a in result:\n",
        "    print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjPIdunblwdh"
      },
      "source": [
        "### 2-2　取得したデータをData Frameとして保存する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MJIa3kEk9EQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "th_list = []\n",
        "td_list = []\n",
        "for a in soup.find_all('th'):\n",
        "    th_list.append(a.string)\n",
        "\n",
        "for a in soup.find_all('td'):\n",
        "    td_list.append(a.string)\n",
        "\n",
        "df = pd.DataFrame(np.array([th_list, td_list]).T, columns=['項目', '値'])\n",
        "\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9H81evIfg77"
      },
      "source": [
        "df.to_csv('data.csv', index=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9zjNWuFlVnX"
      },
      "source": [
        "# 演習３　画像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymyjEf0FYdSD"
      },
      "source": [
        "r = requests.get('https://chonholee.github.io/tutorial/bigdata/test-image.html')\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blj6WeXYYihR"
      },
      "source": [
        "soup.find('img') # 一つ\n",
        "soup.find_all('img') # 全部"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtxnCaUImIHn"
      },
      "source": [
        "soup.find('img')['src']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHULAiOBm6tk"
      },
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "page_dir = 'https://chonholee.github.io/tutorial/bigdata/'\n",
        "\n",
        "img_url = soup.find('img')['src']\n",
        "\n",
        "img_binary = io.BytesIO(requests.get(page_dir+img_url).content) #画像のURLから画像をバイナリーデータに変換\n",
        "\n",
        "img = Image.open(img_binary) #バイナリーデータを画像化"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpsjHJkl4Sqs"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1VjRuPG4ytS"
      },
      "source": [
        "### 3-2 imgタグすべてを取得して画像を保存する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftyOE7lM4md4"
      },
      "source": [
        "img_tag_list = soup.find_all('img') #imgタグをすべて取得\n",
        "\n",
        "for i, img_tag in enumerate(img_tag_list):\n",
        "    img_url = img_tag['src'] #画像URL取得\n",
        "    img_binary = io.BytesIO(requests.get(page_dir+img_url).content) #バイナリーデータ化\n",
        "    img = Image.open(img_binary) #画像化\n",
        "    img.save('{}.jpg'.format(i)) #保存"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUhSd_bNhYht"
      },
      "source": [
        "# 演習４　プロ野球データ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACZnSluYhYGw"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as BS\n",
        "\n",
        "# HTMLを取得\n",
        "url = 'https://baseball-data.com/stats/hitter2-all/tpa-2.html'\n",
        "res = requests.get(url)\n",
        "content = res.text"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHglwuuGhjq6"
      },
      "source": [
        "content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmgqTTR4ntDQ"
      },
      "source": [
        "## htmlコードを見て、取得したいデータのタグを検証する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azdbXLJ5hu8Z"
      },
      "source": [
        "# table 要素を取得\n",
        "bs = BS(content, \"lxml\")  # parserの高速化　https://naruport.com/blog/2019/7/13/how-to-use-of-beautiful-soup-4/\n",
        "tables = bs.find_all(\"table\")\n",
        "n_tables = len(tables)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke6F1jpxiXYh"
      },
      "source": [
        "tables\n",
        "\n",
        "#抽出したテーブルが複数ある場合\n",
        "if n_tables > 1:\n",
        "    for i in range(n_tables):\n",
        "        print(tables[i])            "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCVYF_mLiQlt"
      },
      "source": [
        "# table head 要素を取得 (存在する場合)\n",
        "thead = table.find(\"thead\")\n",
        "\n",
        "# thead が存在する場合\n",
        "if thead:\n",
        "    tr = thead.find(\"tr\")\n",
        "    ths = tr.find_all(\"th\")\n",
        "    columns = [th.text for th in ths]    # pandas.DataFrame を意識\n",
        "# thead が存在しない場合\n",
        "else:\n",
        "    columns = []\n",
        "\n",
        "columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7kmxCNQlPHP"
      },
      "source": [
        "# table body 要素を取得\n",
        "tbody = table.find(\"tbody\")\n",
        "\n",
        "# tr 要素を取得\n",
        "trs = tbody.find_all(\"tr\")\n",
        "\n",
        "# 出力したい行データ\n",
        "rows = [columns]\n",
        "\n",
        "# td (th) 要素の値を読み込む\n",
        "for tr in trs:\n",
        "    row = [td.text for td in tr.find_all([\"td\"])]\n",
        "    rows.append(row)\n",
        "\n",
        "rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64ivoDrGleFG"
      },
      "source": [
        "# データを書き込む\n",
        "import csv\n",
        "\n",
        "filepath = \"baseball_data.csv\"\n",
        "\n",
        "with open(filepath, \"w\") as f:\n",
        "    writer = csv.writer(f, lineterminator=\"\\n\")\n",
        "    writer.writerows(rows)"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}