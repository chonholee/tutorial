{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chonholee/tutorial/blob/main/ml/ML04_1_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcaNyqDG2V8H"
      },
      "source": [
        "# 演習４　K近傍回帰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGxXFtMA1r_K"
      },
      "source": [
        "mglearnライブラリを利用したｋ近傍回帰の例\n",
        "\n",
        "※ｋ近傍回帰のアルゴリズムの実装ではありません"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO0fnlpQwWvZ"
      },
      "outputs": [],
      "source": [
        "!pip install mglearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uE2XHFJwfQy"
      },
      "outputs": [],
      "source": [
        "import mglearn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 適当にデータセットを作成\n",
        "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
        "plt.plot(X, y, 'o')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPU-39HN2V8O"
      },
      "source": [
        "### まずは sklearn ライブラリで用意されているｋ近傍回帰のアルゴリズムを動かしてみる\n",
        "\n",
        "※ｋ近傍回帰アルゴリズムの実装ではありません"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjnWcrNY2V8O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import euclidean_distances\n",
        "\n",
        "cm3 = ListedColormap(['#0000aa', '#ff2020', '#50ff50'])\n",
        "\n",
        "def plot_knn_regression(n_neighbors=1):\n",
        "\n",
        "    dist = euclidean_distances(X, X_test)\n",
        "    closest = np.argsort(dist, axis=0)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    reg = KNeighborsRegressor(n_neighbors=n_neighbors).fit(X, y)\n",
        "    y_pred = reg.predict(X_test)\n",
        "\n",
        "    for x, y_, neighbors in zip(X_test, y_pred, closest.T):\n",
        "        for neighbor in neighbors[:n_neighbors]:\n",
        "                plt.arrow(x[0], y_, X[neighbor, 0] - x[0], y[neighbor] - y_,\n",
        "                          head_width=0, fc='k', ec='k')\n",
        "\n",
        "    train, = plt.plot(X, y, 'o', c=cm3(0))\n",
        "    test, = plt.plot(X_test, -3 * np.ones(len(X_test)), '*', c=cm3(2),\n",
        "                     markersize=20)\n",
        "    pred, = plt.plot(X_test, y_pred, '*', c=cm3(0), markersize=20)\n",
        "    plt.vlines(X_test, -3.1, 3.1, linestyle=\"--\")\n",
        "    plt.legend([train, test, pred],\n",
        "               [\"training data/target\", \"test data\", \"test prediction\"],\n",
        "               ncol=3, loc=(.1, 1.025))\n",
        "    plt.ylim(-3.1, 3.1)\n",
        "    plt.xlabel(\"Feature\")\n",
        "    plt.ylabel(\"Target\")\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfLEJ_pn2V8P"
      },
      "outputs": [],
      "source": [
        "# 学習データ：上で作成済み\n",
        "# X, y = make_wave(n_samples=40)\n",
        "\n",
        "# テストデータ：３つのｘ値（からｙ値を予測する）\n",
        "X_test = np.array([[-1.5], [0.9], [1.5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7_mKqZexN-o"
      },
      "outputs": [],
      "source": [
        "y_test = plot_knn_regression(n_neighbors=1)\n",
        "print('予測値：', y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "groDe5gQ1nav"
      },
      "outputs": [],
      "source": [
        "# 上と同じくｋ＝３の予測値も求めて、図を見ながらなぜそのような予測がされたのか確認してください。\n",
        "\n",
        "--- here ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMQ2fqI42V8Q"
      },
      "outputs": [],
      "source": [
        "# 上と同じくｋ＝３の予測値も求めて、図を見ながらなぜそのような予測がされたのか確認してください。\n",
        "\n",
        "--- here ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DCv1DID2V8R"
      },
      "source": [
        "### 学習モデルの精度を検証してみる\n",
        "\n",
        "ｋの値によってモデルの精度が異なることを確認してください。\n",
        "\n",
        "* 水色の線：学習データセットから計算された予測値\n",
        "* 青三角：学習データ\n",
        "* 赤三角：テストデータ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmnKoq_12V8R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
        "\n",
        "# データセットを学習データとテストデータに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "# instantiate the model and set the number of neighbors to consider to 3\n",
        "reg = KNeighborsRegressor(n_neighbors=3)\n",
        "# fit the model using the training data and training targets\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "# create 1,000 data points, evenly spaced between -3 and 3\n",
        "line = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
        "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
        "    # make predictions using 1, 3, or 9 neighbors\n",
        "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
        "    reg.fit(X_train, y_train)\n",
        "    ax.plot(line, reg.predict(line))\n",
        "    ax.plot(X_train, y_train, '^', c=mglearn.cm2(0),\n",
        "             markersize=8)\n",
        "    ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
        "    ax.set_title(\"{} neighbor(s)\\n train score: {:.2f} testscore: {:.2f}\".format(n_neighbors,\n",
        "              reg.score(X_train, y_train),reg.score(X_test, y_test)))\n",
        "    ax.set_xlabel(\"Feature\")\n",
        "    ax.set_ylabel(\"Target\")\n",
        "axes[0].legend([\"Model predictions\", \"Training data/target\",\"Testdata/target\"], loc=\"best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u99NoSFe2V8R"
      },
      "source": [
        "### ｋ近傍回帰アルゴリズムの実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BleRbQco2V8R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class KNNRegression:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            # 距離の計算\n",
        "            distances = np.sqrt(np.sum((self.X_train - x) ** 2, axis=1))\n",
        "            # 近い順にソート\n",
        "            indices = np.argsort(distances)[:self.k]\n",
        "            # ｋの値に応じた平均値を計算\n",
        "            neighbors = self.y_train[indices]\n",
        "            prediction = np.mean(neighbors)\n",
        "            predictions.append(prediction)\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ex6kM252V8S"
      },
      "outputs": [],
      "source": [
        "# データの準備\n",
        "X_train = np.array([[1.1], [2.2], [3.3], [4.4], [5.5]])\n",
        "y_train = np.array([2, 4, 6, 8, 10])\n",
        "X_test = np.array([[2.5], [4.5]])\n",
        "\n",
        "# KNN回帰モデルの作成と学習\n",
        "--- here ---\n",
        "\n",
        "\n",
        "# テストデータに対する予測\n",
        "--- here ---\n",
        "\n",
        "\n",
        "print(X_test)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoZBI4GG2V8S"
      },
      "outputs": [],
      "source": [
        "# プロットしてみる\n",
        "plt.plot(X_train, y_train, 'o')\n",
        "plt.plot(X_test, predictions, 'o')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}